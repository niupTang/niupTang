---
title: Github 64.7k Star GPT å­¦æœ¯ä¼˜åŒ–
date: 2024-10-11 22:58:35
tags:
  - å…¬ä¼—å?
  - åŸåˆ›
categories:
  - å…¬ä¼—å·æ–‡ç«?
---

* æˆ³ä¸Šæ–¹è“å­—â€?*ç‰›çš®ç³–ä¸å¹ç‰›**â€å…³æ³¨æˆ‘

Â Â Â Â å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ç‰›çš®ç³–ï¼AI çš„é¡¹ç›®çœŸçš„å¤ªç«äº†ï¼ŒGPT çš„æç¤ºè¯é¡¹ç›®åœ¨GitHub ä¸Šé¢å±‚å‡ºä¸ç©·ï¼Œä¸ºGPT/GLMç­‰LLMå¤§è¯­è¨€æ¨¡å‹æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ?è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒchatglm3ç­‰æœ¬åœ°æ¨¡å‹ã€‚æ¥å…¥é€šä¹‰åƒé—®, deepseekcoder, è®¯é£æ˜Ÿç«, æ–‡å¿ƒä¸€è¨€, llama2, rwkv, claude2, mossç­‰ã€‚ä¹Ÿè·å–çš?4.7K Starã€?

****

**![](https://mmbiz.qpic.cn/mmbiz_png/p1ESIQQvfrS4mjzbP7mmu4NNkxlUbcVD2tFYpfTTBIrCic0WrL4tcaw2Vg4cib6lAzhI6Dz8KmZiaj7icH676D1JvA/640?wx_fmt=png&from=appmsg)
**

****

åŠŸèƒ½ï¼ˆâ­= è¿‘æœŸæ–°å¢åŠŸèƒ½ï¼‰æè¿°â­æ¥å…¥æ–°æ¨¡å‹ç™¾åº¦åƒå¸†ä¸æ–‡å¿ƒä¸€è¨€, é€šä¹‰åƒé—®Qwenï¼Œä¸Šæµ·AI-Labä¹¦ç”Ÿï¼Œè®¯é£æ˜Ÿç«ï¼ŒLLaMa2ï¼Œæ™ºè°±GLM4ï¼ŒDALLE3,Â DeepseekCoderâ­æ”¯æŒmermaidå›¾åƒæ¸²æŸ“æ”¯æŒè®©GPTç”Ÿæˆæµç¨‹å›¾ã€çŠ¶æ€è½¬ç§»å›¾ã€ç”˜ç‰¹å›¾ã€é¥¼çŠ¶å›¾ã€GitGraphç­‰ç­‰ï¼?.7ç‰ˆæœ¬ï¼‰â­Arxivè®ºæ–‡ç²¾ç»†ç¿»è¯‘ (Docker)[æ’ä»¶] ä¸€é”®ä»¥è¶…é«˜è´¨é‡ç¿»è¯‘arxivè®ºæ–‡ï¼Œç›®å‰æœ€å¥½çš„è®ºæ–‡ç¿»è¯‘å·¥å…·â­å®æ—¶è¯­éŸ³å¯¹è¯è¾“å…¥[æ’ä»¶] å¼‚æ­¥ç›‘å¬éŸ³é¢‘ï¼Œè‡ªåŠ¨æ–­å¥ï¼Œè‡ªåŠ¨å¯»æ‰¾å›ç­”æ—¶æœºâ­AutoGenå¤šæ™ºèƒ½ä½“æ’ä»¶[æ’ä»¶] å€ŸåŠ©å¾®è½¯AutoGenï¼Œæ¢ç´¢å¤šAgentçš„æ™ºèƒ½æ¶Œç°å¯èƒ½ï¼â­è™šç©ºç»ˆç«¯æ’ä»¶[æ’ä»¶] èƒ½å¤Ÿä½¿ç”¨è‡ªç„¶è¯­è¨€ç›´æ¥è°ƒåº¦æœ¬é¡¹ç›®å…¶ä»–æ’ä»¶æ¶¦è‰²ã€ç¿»è¯‘ã€ä»£ç è§£é‡Šä¸€é”®æ¶¦è‰²ã€ç¿»è¯‘ã€æŸ¥æ‰¾è®ºæ–‡è¯­æ³•é”™è¯¯ã€è§£é‡Šä»£ç è‡ªå®šä¹‰å¿«æ·é”®æ”¯æŒè‡ªå®šä¹‰å¿«æ·é”®æ¨¡å—åŒ–è®¾è®¡æ”¯æŒè‡ªå®šä¹‰å¼ºå¤§çš„æ’ä»¶ï¼Œæ’ä»¶æ”¯æŒçƒ­æ›´æ–°ç¨‹åºå‰–æ[æ’ä»¶] ä¸€é”®å‰–æPython/C/C++/Java/Lua/...é¡¹ç›®æ ?æˆ–Â è‡ªæˆ‘å‰–æè¯»è®ºæ–‡ã€ç¿»è¯‘è®ºæ–‡[æ’ä»¶] ä¸€é”®è§£è¯»latex/pdfè®ºæ–‡å…¨æ–‡å¹¶ç”Ÿæˆæ‘˜è¦Latexå…¨æ–‡ç¿»è¯‘ã€æ¶¦è‰²[æ’ä»¶] ä¸€é”®ç¿»è¯‘æˆ–æ¶¦è‰²latexè®ºæ–‡æ‰¹é‡æ³¨é‡Šç”Ÿæˆ[æ’ä»¶] ä¸€é”®æ‰¹é‡ç”Ÿæˆå‡½æ•°æ³¨é‡ŠMarkdownä¸­è‹±äº’è¯‘[æ’ä»¶] çœ‹åˆ°ä¸Šé¢5ç§è¯­è¨€çš„READMEäº†å—ï¼Ÿå°±æ˜¯å‡ºè‡ªä»–çš„æ‰‹ç¬”PDFè®ºæ–‡å…¨æ–‡ç¿»è¯‘åŠŸèƒ½[æ’ä»¶] PDFè®ºæ–‡æå–é¢˜ç›®&æ‘˜è¦+ç¿»è¯‘å…¨æ–‡ï¼ˆå¤šçº¿ç¨‹ï¼‰Arxivå°åŠ©æ‰‹[æ’ä»¶] è¾“å…¥arxivæ–‡ç« urlå³å¯ä¸€é”®ç¿»è¯‘æ‘˜è¦?ä¸‹è½½PDFLatexè®ºæ–‡ä¸€é”®æ ¡å¯¹[æ’ä»¶] ä»¿Grammarlyå¯¹Latexæ–‡ç« è¿›è¡Œè¯­æ³•ã€æ‹¼å†™çº é”?è¾“å‡ºå¯¹ç…§PDFè°·æ­Œå­¦æœ¯ç»Ÿåˆå°åŠ©æ‰‹[æ’ä»¶] ç»™å®šä»»æ„è°·æ­Œå­¦æœ¯æœç´¢é¡µé¢URLï¼Œè®©gptå¸®ä½ å†™relatedworksäº’è”ç½‘ä¿¡æ¯èšå?GPT[æ’ä»¶] ä¸€é”®è®©GPTä»äº’è”ç½‘è·å–ä¿¡æ¯å›ç­”é—®é¢˜ï¼Œè®©ä¿¡æ¯æ°¸ä¸è¿‡æ—¶å…¬å¼/å›¾ç‰‡/è¡¨æ ¼æ˜¾ç¤ºå¯ä»¥åŒæ—¶æ˜¾ç¤ºå…¬å¼çš„texå½¢å¼å’Œæ¸²æŸ“å½¢å¼ï¼Œæ”¯æŒå…¬å¼ã€ä»£ç é«˜äº®å¯åŠ¨æš—è‰²ä¸»é¢˜åœ¨æµè§ˆå™¨urlåé¢æ·»åŠ /?__theme=darkå¯ä»¥åˆ‡æ¢darkä¸»é¢˜å¤šLLMæ¨¡å‹æ”¯æŒåŒæ—¶è¢«GPT3.5ã€GPT4ã€æ¸…åChatGLM2ã€å¤æ—¦MOSSä¼ºå€™çš„æ„Ÿè§‰ä¸€å®šä¼šå¾ˆä¸é”™å§ï¼Ÿæ›´å¤šLLMæ¨¡å‹æ¥å…¥ï¼Œæ”¯æŒhuggingfaceéƒ¨ç½²åŠ å…¥Newbingæ¥å£(æ–°å¿…åº?ï¼Œå¼•å…¥æ¸…åJittorllmsæ”¯æŒLLaMAå’Œç›˜å¤Î±â­void-terminalÂ pipåŒ…è„±ç¦»GUIï¼Œåœ¨Pythonä¸­ç›´æ¥è°ƒç”¨æœ¬é¡¹ç›®çš„æ‰€æœ‰å‡½æ•°æ’ä»¶ï¼ˆå¼€å‘ä¸­ï¼?***![](https://mmbiz.qpic.cn/mmbiz_png/p1ESIQQvfrS4mjzbP7mmu4NNkxlUbcVDI3IlZ0pXZXqIfrC5J7kiccvK0Ps02u1fBG72T7YIicD24ntWAAXSX97A/640?wx_fmt=png&from=appmsg)
****

**
**

**å®‰è£…**

**
**

éƒ¨ç½²é¡¹ç›®çš„å…¨éƒ¨èƒ½åŠ›ï¼ˆè¿™ä¸ªæ˜¯åŒ…å«cudaå’Œlatexçš„å¤§å‹é•œåƒã€‚ä½†å¦‚æœæ‚¨ç½‘é€Ÿæ…¢ã€ç¡¬ç›˜å°ï¼Œåˆ™ä¸æ¨èè¯¥æ–¹æ³•éƒ¨ç½²å®Œæ•´é¡¹ç›®ï¼‰Â?

# ä¿®æ”¹docker-compose.ymlï¼Œä¿ç•™æ–¹æ¡?å¹¶åˆ é™¤å…¶ä»–æ–¹æ¡ˆã€‚ç„¶åè¿è¡Œï¼šdocker-compose```

```
```

```
```
ä»…ChatGPT + GLM4 + æ–‡å¿ƒä¸€è¨€+sparkç­‰åœ¨çº¿æ¨¡å‹ï¼ˆæ¨èå¤§å¤šæ•°äººé€‰æ‹©ï¼‰Â Â Â?

```
```
# ä¿®æ”¹docker-compose.ymlï¼Œä¿ç•™æ–¹æ¡?å¹¶åˆ é™¤å…¶ä»–æ–¹æ¡ˆã€‚ç„¶åè¿è¡Œï¼š
```

- 
`docker-compose up`

**Docker-compose.yml æ–‡ä»¶
**
- 
`## ===================================================``#                docker-compose.yml``## 
===================================================``# 1. è¯·åœ¨ä»¥ä¸‹æ–¹æ¡ˆä¸­é€‰æ‹©ä»»æ„ä¸€ç§ï¼Œç„¶ååˆ é™¤å…¶ä»–çš„æ–¹æ¡ˆ``# 2. ä¿®æ”¹ä½ é€‰æ‹©çš„æ–¹æ¡ˆä¸­çš„environmentç¯å¢ƒå˜é‡ï¼Œè¯¦æƒ…è¯·è§github wikiæˆ–è€…config.py``# 3. é€‰æ‹©ä¸€ç§æš´éœ²æœåŠ¡ç«¯å£çš„æ–¹æ³•ï¼Œå¹¶å¯¹ç›¸åº”çš„é…ç½®åšå‡ºä¿®æ”¹ï¼š``    # ã€Œæ–¹æ³?: é€‚ç”¨äºLinuxï¼Œå¾ˆæ–¹ä¾¿ï¼Œå¯æƒœwindowsä¸æ”¯æŒã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆä¸ºä¸€ä½“ï¼Œè¿™ä¸ªæ˜¯é»˜è®¤é…ç½®``    # network_mode: "host"``    # ã€Œæ–¹æ³?: é€‚ç”¨äºæ‰€æœ‰ç³»ç»ŸåŒ…æ‹¬Windowså’ŒMacOSã€ç«¯å£æ˜ å°„ï¼ŒæŠŠå®¹å™¨çš„ç«¯å£æ˜ å°„åˆ°å®¿ä¸»çš„ç«¯å£ï¼ˆæ³¨æ„æ‚¨éœ€è¦å…ˆåˆ é™¤network_mode: "host"ï¼Œå†è¿½åŠ ä»¥ä¸‹å†…å®¹ï¼‰``    # ports:``    #   - "12345:12345"  # æ³¨æ„ï¼?2345å¿…é¡»ä¸WEB_PORTç¯å¢ƒå˜é‡ç›¸äº’å¯¹åº”``# 4. æœ€å`docker-compose up`è¿è¡Œ``# 5. å¦‚æœå¸Œæœ›ä½¿ç”¨æ˜¾å¡ï¼Œè¯·å…³æ³¨ LOCAL_MODEL_DEVICE å’?è‹±ä¼Ÿè¾¾æ˜¾å¡è¿è¡Œæ—¶ é€‰é¡¹``## ===================================================``# 1. Please choose one of the following options and delete the others.``# 2. Modify the environment variables in the selected option, see GitHub wiki or config.py for more details.``# 3. Choose a method to expose the server port and make the corresponding configuration changes:``    # [Method 1: Suitable for Linux, convenient, but not supported for Windows] Fusion with the host network, this is the default configuration``    # network_mode: "host"``    # [Method 2: Suitable for all systems including Windows and MacOS] Port mapping, mapping the container port to the host port (note that you need to delete network_mode: "host" first, and then add the following content)``    # ports:``    # - "12345: 12345" # Note! 12345 must correspond to the WEB_PORT environment variable.``# 4. Finally, run `docker-compose up`.``# 5. If you want to use a graphics card, pay attention to the LOCAL_MODEL_DEVICE and Nvidia GPU runtime options.``## ===================================================``
``## ===================================================``## ã€Œæ–¹æ¡ˆé›¶ã€?éƒ¨ç½²é¡¹ç›®çš„å…¨éƒ¨èƒ½åŠ›ï¼ˆè¿™ä¸ªæ˜¯åŒ…å«cudaå’Œlatexçš„å¤§å‹é•œåƒã€‚å¦‚æœæ‚¨ç½‘é€Ÿæ…¢ã€ç¡¬ç›˜å°æˆ–æ²¡æœ‰æ˜¾å¡ï¼Œåˆ™ä¸æ¨èä½¿ç”¨è¿™ä¸ªï¼‰``## ===================================================``version: '3'``services:``  gpt_academic_full_capability:``    image: ghcr.io/binary-husky/gpt_academic_with_all_capacity:master``    environment:``      # è¯·æŸ¥é˜?`config.py`æˆ–è€?github wiki ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é…ç½®ä¿¡æ¯``      API_KEY:                  '  sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                        '``      # USE_PROXY:                '  True                                                                       '``      # proxies:                  '  { "http": "http://localhost:10881", "https": "http://localhost:10881", }   '``      LLM_MODEL:                '  gpt-3.5-turbo                                                              '``      AVAIL_LLM_MODELS:         '  ["gpt-3.5-turbo", "gpt-4", "qianfan", "sparkv2", "spark", "chatglm"]       '``      BAIDU_CLOUD_API_KEY :     '  xxxxxxxxxxxxxxxxxxxxxxxx                                                   '``      BAIDU_CLOUD_SECRET_KEY :  '  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                           '``      XFYUN_APPID:              '  xxxxxxxx                                                                   '``      XFYUN_API_SECRET:         '  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                           '``      XFYUN_API_KEY:            '  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                           '``      ENABLE_AUDIO:             '  False                                                                      '``      DEFAULT_WORKER_NUM:       '  20                                                                         '``      WEB_PORT:                 '  12345                                                                      '``      ADD_WAIFU:                '  False                                                                      '``      ALIYUN_APPKEY:            '  xxxxxxxxxxxxxxxx                                                           '``      THEME:                    '  Chuanhu-Small-and-Beautiful                                                '``      ALIYUN_ACCESSKEY:         '  xxxxxxxxxxxxxxxxxxxxxxxx                                                   '``      ALIYUN_SECRET:            '  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                             '``      # LOCAL_MODEL_DEVICE:       '  cuda                                                                       '``
``    # åŠ è½½è‹±ä¼Ÿè¾¾æ˜¾å¡è¿è¡Œæ—¶``    # runtime: nvidia``    # deploy:``    #     resources:``    #       reservations:``    #         devices:``    #           - driver: nvidia``    #             count: 1``    #             capabilities: [gpu]``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•1: é€‚ç”¨äºLinuxã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆ``    network_mode: "host"``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•2: é€‚ç”¨äºæ‰€æœ‰ç³»ç»Ÿã€ç«¯å£æ˜ å°„``    # ports:``    #   - "12345:12345"  # 12345å¿…é¡»ä¸WEB_PORTç›¸äº’å¯¹åº”``
``    # å¯åŠ¨å®¹å™¨åï¼Œè¿è¡Œmain.pyä¸»ç¨‹åº``    command: >``      bash -c "python3 -u main.py"``
``
``## ===================================================``## ã€Œæ–¹æ¡ˆä¸€ã€?å¦‚æœä¸éœ€è¦è¿è¡Œæœ¬åœ°æ¨¡å‹ï¼ˆä»?chatgpt, azure, æ˜Ÿç«, åƒå¸†, claude ç­‰åœ¨çº¿å¤§æ¨¡å‹æœåŠ¡ï¼‰``## ===================================================``version: '3'``services:``  gpt_academic_nolocalllms:``    image: ghcr.io/binary-husky/gpt_academic_nolocal:master # (Auto Built by Dockerfile: docs/GithubAction+NoLocal)``    environment:``      # è¯·æŸ¥é˜?`config.py` ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é…ç½®ä¿¡æ¯``      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                            '``      USE_PROXY:                '    True                                                                                           '``      proxies:                  '    { "http": "socks5h://localhost:10880", "https": "socks5h://localhost:10880", }                 '``      LLM_MODEL:                '    gpt-3.5-turbo                                                                                  '``      AVAIL_LLM_MODELS:         '    ["gpt-3.5-turbo", "api2d-gpt-3.5-turbo", "gpt-4", "api2d-gpt-4", "sparkv2", "qianfan"]         '``      WEB_PORT:                 '    22303                                                                                          '``      ADD_WAIFU:                '    True                                                                                           '``      # THEME:                    '    Chuanhu-Small-and-Beautiful                                                                    '``      # DEFAULT_WORKER_NUM:       '    10                                                                                             '``      # AUTHENTICATION:           '    [("username", "passwd"), ("username2", "passwd2")]                                             '``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•1: é€‚ç”¨äºLinuxã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆ``    network_mode: "host"``
``    # å¯åŠ¨å‘½ä»¤``    command: >``      bash -c "python3 -u main.py"``
``
``### ===================================================``### ã€Œæ–¹æ¡ˆäºŒã€?å¦‚æœéœ€è¦è¿è¡ŒChatGLM + Qwen + MOSSç­‰æœ¬åœ°æ¨¡å‹``### ===================================================``version: '3'``services:``  gpt_academic_with_chatglm:``    image: ghcr.io/binary-husky/gpt_academic_chatglm_moss:master  # (Auto Built by Dockerfile: docs/Dockerfile+ChatGLM)``    environment:``      # è¯·æŸ¥é˜?`config.py` ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é…ç½®ä¿¡æ¯``      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                            '``      USE_PROXY:                '    True                                                                                           '``      proxies:                  '    { "http": "socks5h://localhost:10880", "https": "socks5h://localhost:10880", }                 '``      LLM_MODEL:                '    gpt-3.5-turbo                                                                                  '``      AVAIL_LLM_MODELS:         '    ["chatglm", "qwen", "moss", "gpt-3.5-turbo", "gpt-4", "newbing"]                               '``      LOCAL_MODEL_DEVICE:       '    cuda                                                                                           '``      DEFAULT_WORKER_NUM:       '    10                                                                                             '``      WEB_PORT:                 '    12303                                                                                          '``      ADD_WAIFU:                '    True                                                                                           '``      # AUTHENTICATION:           '    [("username", "passwd"), ("username2", "passwd2")]                                             '``
``    # æ˜¾å¡çš„ä½¿ç”¨ï¼Œnvidia0æŒ‡ç¬¬0ä¸ªGPU``    runtime: nvidia``    devices:``      - /dev/nvidia0:/dev/nvidia0``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•1: é€‚ç”¨äºLinuxã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆ``    network_mode: "host"``
``    # å¯åŠ¨å‘½ä»¤``    command: >``      bash -c "python3 -u main.py"``
``    # P.S. é€šè¿‡å¯?command è¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥ä¾¿æ·åœ°å®‰è£…é¢å¤–çš„ä¾èµ–``    # command: >``    #   bash -c "pip install -r request_llms/requirements_qwen.txt && python3 -u main.py"``
``
``### ===================================================``### ã€Œæ–¹æ¡ˆä¸‰ã€?å¦‚æœéœ€è¦è¿è¡ŒChatGPT + LLAMA + ç›˜å¤ + RWKVæœ¬åœ°æ¨¡å‹``### ===================================================``version: '3'``services:``  gpt_academic_with_rwkv:``    image: ghcr.io/binary-husky/gpt_academic_jittorllms:master``    environment:``      # è¯·æŸ¥é˜?`config.py` ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é…ç½®ä¿¡æ¯``      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,fkxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  '``      USE_PROXY:                '    True                                                                                           '``      proxies:                  '    { "http": "socks5h://localhost:10880", "https": "socks5h://localhost:10880", }                 '``      LLM_MODEL:                '    gpt-3.5-turbo                                                                                  '``      AVAIL_LLM_MODELS:         '    ["gpt-3.5-turbo", "newbing", "jittorllms_rwkv", "jittorllms_pangualpha", "jittorllms_llama"]   '``      LOCAL_MODEL_DEVICE:       '    cuda                                                                                           '``      DEFAULT_WORKER_NUM:       '    10                                                                                             '``      WEB_PORT:                 '    12305                                                                                          '``      ADD_WAIFU:                '    True                                                                                           '``      # AUTHENTICATION:           '    [("username", "passwd"), ("username2", "passwd2")]                                             '``
``    # æ˜¾å¡çš„ä½¿ç”¨ï¼Œnvidia0æŒ‡ç¬¬0ä¸ªGPU``    runtime: nvidia``    devices:``      - /dev/nvidia0:/dev/nvidia0``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•1: é€‚ç”¨äºLinuxã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆ``    network_mode: "host"``
``    # å¯åŠ¨å‘½ä»¤``    command: >``      python3 -u main.py``
``
``## ===================================================``## ã€Œæ–¹æ¡ˆå››ã€?ChatGPT + Latex``## ===================================================``version: '3'``services:``  gpt_academic_with_latex:``    image: ghcr.io/binary-husky/gpt_academic_with_latex:master  # (Auto Built by Dockerfile: docs/GithubAction+NoLocal+Latex)``    environment:``      # è¯·æŸ¥é˜?`config.py` ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é…ç½®ä¿¡æ¯``      API_KEY:                  '    sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                              '``      USE_PROXY:                '    True                                                                             '``      proxies:                  '    { "http": "socks5h://localhost:10880", "https": "socks5h://localhost:10880", }   '``      LLM_MODEL:                '    gpt-3.5-turbo                                                                    '``      AVAIL_LLM_MODELS:         '    ["gpt-3.5-turbo", "gpt-4"]                                                       '``      LOCAL_MODEL_DEVICE:       '    cuda                                                                             '``      DEFAULT_WORKER_NUM:       '    10                                                                               '``      WEB_PORT:                 '    12303                                                                            '``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•1: é€‚ç”¨äºLinuxã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆ``    network_mode: "host"``
``    # å¯åŠ¨å‘½ä»¤``    command: >``      bash -c "python3 -u main.py"``
``
``## ===================================================``## ã€Œæ–¹æ¡ˆäº”ã€?ChatGPT + è¯­éŸ³åŠ©æ‰‹ ï¼ˆè¯·å…ˆé˜…è¯?docs/use_audio.mdï¼‰``## ===================================================``version: '3'``services:``  gpt_academic_with_audio:``    image: ghcr.io/binary-husky/gpt_academic_audio_assistant:master``    environment:``      # è¯·æŸ¥é˜?`config.py` ä»¥æŸ¥çœ‹æ‰€æœ‰çš„é…ç½®ä¿¡æ¯``      API_KEY:                  '    fkxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                        '``      USE_PROXY:                '    False                                                            '``      proxies:                  '    None                                                             '``      LLM_MODEL:                '    gpt-3.5-turbo                                                    '``      AVAIL_LLM_MODELS:         '    ["gpt-3.5-turbo", "gpt-4"]                                       '``      ENABLE_AUDIO:             '    True                                                             '``      LOCAL_MODEL_DEVICE:       '    cuda                                                             '``      DEFAULT_WORKER_NUM:       '    20                                                               '``      WEB_PORT:                 '    12343                                                            '``      ADD_WAIFU:                '    True                                                             '``      THEME:                    '    Chuanhu-Small-and-Beautiful                                      '``      ALIYUN_APPKEY:            '    xxxxxxxxxxxxxxxx                                                 '``      ALIYUN_TOKEN:             '    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                 '``      # (æ— éœ€å¡«å†™) ALIYUN_ACCESSKEY:         '    xxxxxxxxxxxxxxxxxxxxxxxx                                         '``      # (æ— éœ€å¡«å†™) ALIYUN_SECRET:            '    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                                   '``
``    # ã€ŒWEB_PORTæš´éœ²æ–¹æ³•1: é€‚ç”¨äºLinuxã€ä¸å®¿ä¸»çš„ç½‘ç»œèåˆ``    network_mode: "host"``
``    # å¯åŠ¨å‘½ä»¤``    command: >``      bash -c "python3 -u main.py"`
****

**
**

é¡¹ç›®åœ°å€ï¼?

**https://github.com/binary-husky/gpt_academic**

![](https://mmbiz.qpic.cn/mmbiz_gif/7ibzJsmgW5wguO21SlkBAdxJgAicEOVCzDiaObyzEAEMTI527clib7gHvKfBtDu8MJZLwwEIVuVBmqfn01fmLDdTfQ/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·ENDÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·

### **æ¨èé˜…è¯»**
â€¢Â?Â [githubÂ 95.5k Star çš„é¡¹ç›®é›†åˆåœ°](http://mp.weixin.qq.com/s?__biz=MzkyNDYyODg0MQ==&mid=2247485137&idx=1&sn=00da6656ecacfcab683c6e149c208985&chksm=c1d3a4d7f6a42dc107aa9233b7a23f20a4bfe7bcd9d48a0fe24787faae37539bd65663d8ba8e&scene=21#wechat_redirect)[â€](http://mp.weixin.qq.com/s?__biz=MzkyNDYyODg0MQ==&mid=2247485121&idx=1&sn=97093dfe7da78fb786bb999a284ee1fc&chksm=c1d3a4c7f6a42dd1df4cb4de4c057671d57274480eac57e61b4f6bae86aef03ff26bf23ffdd6&scene=21#wechat_redirect)â€¢Â?Â [4æ ?16G å°±èƒ½ RAGFlow Quick start å¿«é€Ÿå…¥é—¨](http://mp.weixin.qq.com/s?__biz=MzkyNDYyODg0MQ==&mid=2247485121&idx=1&sn=97093dfe7da78fb786bb999a284ee1fc&chksm=c1d3a4c7f6a42dd1df4cb4de4c057671d57274480eac57e61b4f6bae86aef03ff26bf23ffdd6&scene=21#wechat_redirect)â€¢Â Â Â [github 7.8k star å°†å°çˆ±éŸ³ç®±æ¥å…?ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±è¯­éŸ³åŠ©æ‰‹ã€‚](http://mp.weixin.qq.com/s?__biz=MzIxODg1OTk1MA==&mid=2247488494&idx=1&sn=0244c0a45012f5a6ca6cdf9a0ac88024&chksm=97e5432fa092ca39991868bda959cfd8bafd949fa445ef72bdca5cc6c4dc2ed4bd51e22634f8&scene=21#wechat_redirect)

**
**