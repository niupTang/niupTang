---
title: 一个项目教会你如何学习大语言模型
date: 2024-06-05 17:14:11
tags:
  - 公众?
  - 原创
categories:
  - 公众号文?
---

### 1.1 大型语言模型（LLM）的概念
大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型?

LLM 通常指包含数百亿（或更多）参数的语言模型，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知?LLM ?GPT-3.5、GPT-4、PaLM、Claude ?LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等?

为了探索性能的极限，许多研究人员开始训练越来越庞大的语言模型，例如拥有 `1750 亿`参数的 `GPT-3` 和 `5400 亿`参数的 `PaLM` 。尽管这些大型语言模型与小型语言模型（例如 `3.3 亿`参数的 `BERT` 和 `15 亿`参数的 `GPT-2`）使用相似的架构和预训练任务，但它们展现出截然不同的能力，尤其在解决复杂任务时表现出了惊人的潜力，这被称为“涌现能力”。以 GPT-3 ?GPT-2 为例，GPT-3 可以通过学习上下文来解决少样本任务，?GPT-2 在这方面表现较差。因此，科研界给这些庞大的语言模型起了个名字，称之为“大语言模型（LLM）”。LLM 的一个杰出应用就是 ChatGPT ，它?GPT 系列 LLM 用于与人类对话式应用的大胆尝试，展现出了非常流畅和自然的表现?

### 1.2 大型语言模型（LLM）的学习方向
![](https://mmbiz.qpic.cn/mmbiz_jpg/p1ESIQQvfrTMicrYPCghhaYcnhgj3OSibjaibhQUPfj5N0xbAHX75gb3lpFvhvPM0E6iabYIbLZEycUxcEu3ZWicKbw/640?wx_fmt=jpeg&from=appmsg)

   大模型的基本开发，相对来说是比较简单的，只需要针对于大模型的一些应用和一些想方法来进行接口接入?

 1.2.1 使用智谱 GLM API接入

https://open.bigmodel.cn/

![](https://mmbiz.qpic.cn/mmbiz_png/p1ESIQQvfrTMicrYPCghhaYcnhgj3OSibjAu536BF1v5g75eYWHwavoSlBXGWTe3d1C6JKdxwrk3RehFu6G1JVJQ/640?wx_fmt=png&from=appmsg)

  比如调用使用智谱 GLM ，智?AI 提供?SDK 和原?HTTP 来实现模?API 的调用，建议使用 SDK 进行调用以获得更好的编程体验?

![](https://mmbiz.qpic.cn/mmbiz_png/p1ESIQQvfrTMicrYPCghhaYcnhgj3OSibjUQ2HwOtuI9uSPU7NWXWn5ISdw8lERyWRscqNgamwZzsX9t4afmdicww/640?wx_fmt=png&from=appmsg)

首先我们需要配置密钥信息，将前面获取到的 `API key` 设置到 `.env` 文件中的 `ZHIPUAI_API_KEY` 参数，然后运行以下代码加载配置信息?

`import os

from dotenv import load_dotenv, find_dotenv

# 读取本地/项目的环境变量?

# find_dotenv() 寻找并定?.env 文件的路?
# load_dotenv() 读取?.env 文件，并将其中的环境变量加载到当前的运行环境? 
# 如果你设置的是全局的环境变量，这行代码则没有任何作用?
_ = load_dotenv(find_dotenv())````

- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
`from zhipuai import ZhipuAI``
``client = ZhipuAI(``    api_key=os.environ["ZHIPUAI_API_KEY"]``)``
``def gen_glm_params(prompt):``    '''``    构?GLM 模型请求参数 messages``
``    请求参数：``        prompt: 对应的用户提示词``    '''``    messages = [{"role": "user", "content": prompt}]``    return messages``    ``def get_completion(prompt, model="glm-4", temperature=0.95):``    '''``    获取 GLM 模型调用结果``
``    请求参数：``        prompt: 对应的提示词``        model: 调用的模型，默认?glm-4，也可以按需选择 glm-3-turbo 等其他模型``        temperature: 模型输出的温度系数，控制输出的随机程度，取值范围是 0~1.0，且不能设置?0。温度系数越低，输出内容越一致。``    '''``
``    messages = gen_glm_params(prompt)``    response = client.chat.completions.create(``        model=model,``        messages=messages,``        temperature=temperature``    )``    if len(response.choices) > 0:``        return response.choices[0].message.content``    return "generate answer error"`
```

`1.2.2 搭建向量数据库`

在搭?RAG 系统时，我们往往可以通过使用嵌入模型来构建词向量，我们可以选择?

- 使用各个公司?Embedding API?

- 在本地使用嵌入模型将数据构建为词向量?

    向量数据库是用于高效计算和管理大量向量数据的解决方案。向量数据库是一种专门用于存储和检索向量数据（embedding）的数据库系统。它与传统的基于关系模型的数据库不同，它主要关注的是向量数据的特性和相似性?

    在向量数据库中，数据被表示为向量形式，每个向量代表一个数据项。这些向量可以是数字、文本、图像或其他类型的数据。向量数据库使用高效的索引和查询算法来加速向量数据的存储和检索过程?

主流的向量数据库

- Chroma：是一个轻量级向量数据库，拥有丰富的功能和简单的 API，具有简单、易用、轻量的优点，但功能相对简单且不支持GPU加速，适合初学者使用?

- Weaviate：是一个开源向量数据库。除了支持相似度搜索和最大边际相关性（MMR，Maximal Marginal Relevance）搜索外还可以支持结合多种搜索算法（基于词法搜索、向量搜索）的混合搜索，从而搜索提高结果的相关性和准确性?

- Qdrant：Qdrant使用 Rust 语言开发，有极高的检索效率和RPS（Requests Per Second），支持本地运行、部署在本地服务器及Qdrant云三种部署模式。且可以通过为页面内容和元数据制定不同的键来复用数据?

`具体的内容可以查?https://datawhalechina.github.io/llm-universe`